---

title: "Data Based"  
date: 2021-04-13T15:15:26+10:00  
featured: true  
weight: 3  
layout: service

---

There's no shortage of people or systems claiming to have the right or best way to do things. And most of them have the white papers and research to back it up. So how does one navigate these competing and sometimes contradictory approaches? Even if you do move forward with a particular method of organization, how do you know if you've achieved the results you're supposed to or how do you know that you've implemented it properly and gotten the promised benefits? One problem with this is it frequently, peoples subjective feelings related to working hard and getting things done become the standard of success. This is highly problematic and I don't need to go to Great Lengths to prove that. With money, resources, end time on the line, we should not be relying on subjective impressions of improvement.

## Data-Based Goals and Results

One of the most prominent convictions and values of the Dragon agility group is 2 increase the rigor of agile methods. This means establishing Baseline metrics for a system before implementing changes such that the impact of those changes can be empirically and objectively measured after. Now exactly what those metrics are may change with time and with learning and as well what those practices are will change put the relationship in the priority of a measure-test-measure feedback loop should not change.

## Measuring delivery

Agile delivery metrics have been treated like Alchemy for far too long. The confusion could not be deeper regarding what produces a predictable and stable software delivery system. In fact, it was the very concerned in this area that prompted to birth of the Dragon agility group. We have gone to Great Lengths to cut through the fud on this issue and produced a rigorous and comprehensive method for measuring and improving the rate and predictability of software delivery. We've even gone so far as to instantiate our methodology into a software tool called Animus BI. 

\[Agile Delivery Metrics\]

## Measuring culture

What about the intangibles you ask. What about the human element? We are in fact dealing with people not machines. Once again, this doesn't mean that we don't try to understand things in it structured in measurable way. It's for this reason that we prescribe and practice regular pulse checks of individual and team satisfaction and subjective experience of work. We do this through surveys and interviews immediately following onboarding training, exit interviews, and regular pulse surveys. 

## Program Evaluation

We offer a program evaluation service that can get you started down this road of empirical evaluation and analysis. It involves the following:

1.  We start by establishing a basic model have your delivery system
2.  Second, we establish what metrics can be ascertained from the existing system
3.  Thirdly, using your model and available metrics we establish the best available Baseline for how effectively you currently operate
4.  Lastly, we provide a report suggesting changes to your model and available metrics that would produce a higher fidelity and more controllable system

Armed with the above leadership can then make more informed decisions on areas of growth are possible next steps. One could compare it to a physical examination prior to starting a new training routine. The results of the physical should and would inform the parameters of that new training regime.
